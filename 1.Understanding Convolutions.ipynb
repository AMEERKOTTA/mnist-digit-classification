{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Concepts behind Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instances of Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ CNNs is a special kind of Neural Network which uses identical copies of the same neuron. These copies include the same parameters (weights and biases) and activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location and type of Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ In a fully connected neural network layer, each neuron in the current layer is connected to every neuron in the previous layer, and each connection has its own weights.\n",
    "\n",
    "+ In Convolutional Neural Network layer, each neuron is only connected to a few nearby local neurons in the previous layer, and the same sets of weights are used to connect them.\n",
    "\n",
    "+ Example: the neurons in h1 layer are connected only to some input units\n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/mev168hepixnmc9zhh4hsr3t2ks3rpcc.png\" alt=\"HTML5 Icon\" style=\"width: 500px; height: 500px;\">\n",
    "<center>\n",
    "    \n",
    "figure from Yann Le Cunn's paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Feature Engineering is the process of Extracting useful patterns from input data that will help the prediction model such a way that significantly increases the accuracy and perfomance of the applied ML algorithms\n",
    "\n",
    "+ After Feature Engineering the data should be ready to use in classification or Regression problem\n",
    "\n",
    "+ The advantage of CNN is that, they are good at Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to find a Convolved Feature from an Image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Image Filter</h3>\n",
    "\n",
    "<b>How to create a convolved freature from an image ?</b>  \n",
    "The image below is a 8x8 matrix of an image's pixels, converted to binary values in the next image(left), where 1 means a white pixel and 0 a black pixel. Later we will find out that typically this is a normalization, these values can actually have different scales. The most common usage is values between 0 and 255 for 8-bit grayscale images.  \n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/0s5v7doe2p5xuzifs47bxmmuwrn3kra2.bmp\" alt=\"HTML5 Icon\" style=\"width: 200px; height: 200px;\">\n",
    "<center> An example of a low resolution image to be recognized.\n",
    "\n",
    "In the below image, with an animation, you can see how the two-dimensional convolution operation would operate on the images. This operation is performed in most of the Deep Learning frameworks in their first phase. We need a sliding windows to create the convolved matrix:\n",
    "\n",
    "$\n",
    "kernel=\n",
    "\\begin{bmatrix}\n",
    "     1          & 0      & 1     \\\\\n",
    "     0          & 1    & 0     \\\\\n",
    "     1          & 0    & 1\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "$ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The sliding window (a.k.a kernel, filter or feature detector) with a preset calculation ([[x1, x0,x1], [x0,x1,x0], [x1,x0,x1]]) goes through the image and creates a new matrix (feature map)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"https://ibm.box.com/shared/static/fvutcm8jwa5j2o7xv2zzqyz2yu3zwhz4.gif\" alt=\"HTML5 Icon\" style=\"width: 450px; height: 300px;\">\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above we used a 3×3 filter (5x5 could also be used, but would be too complex). The values from the filter were multiplied element-wise with the original matrix (input image), then summed up. To get the full convolved matrix, the algorithm keep repeating this small procedure for each element by sliding the filter over the whole original matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/7maczejdeej0qoz3pzkysw0y8qb70g2h.png\" alt=\"HTML5 Icon\" style=\"width: 500px; height: 200px;\"> \n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the referenced example,one-dimensional convolution as sliding function (1x1 or 1x2 filter) multiplying and adding on top of an array (1 dimensional array, instead of the original matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Output of applying Kernel on an image\n",
    "+ Output of applying Different kernel to an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/wixvbo9pk0f6r6ln879ah9jjo0ua0fo5.png\" alt=\"HTML5 Icon\" style=\"width: 700px; height: 350px;\"> \n",
    "<center>   Applying the left kernel to the image will result into a blur effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the values −1 and 1 on two adjacent pixels and zero everywhere else for the kernel, results in the following image. That is, we subtract two adjacent pixels. When side by side pixels are similar, this gives us approximately zero. On edges, however, adjacent pixels are very different in the direction perpendicular to the edge. Knowing that results differs from zero will result in brighter pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/z673yijcsfqs5rd8auc1dwmtkejyizv0.png\" alt=\"HTML5 Icon\" style=\"width:700px;height:350px;\">\n",
    "<center> Applying the new left kernel to the image will result into a edge detection, this output is normally useful for the initial layers of a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
